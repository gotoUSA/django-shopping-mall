# ν¬μΈνΈ μ‹μ¤ν… λ¶€ν• ν…μ¤νΈ κ°€μ΄λ“

## π¨ μ¤‘μ”: Celery Worker ν•„μ!

**μ£Όλ¬Έμ΄ λΉ„λ™κΈ°λ΅ μ²λ¦¬λλ―€λ΅ Celery workerκ°€ μ‹¤ν–‰ μ¤‘μ΄μ–΄μ•Ό μ¬κ³ κ°€ μ°¨κ°λ©λ‹λ‹¤.**

## μ‚¬μ „ μ¤€λΉ„

### 1. Redis μ‹¤ν–‰
```bash
# Windows/Mac: Redis μ„¤μΉ ν›„
redis-server

# Docker μ‚¬μ© μ‹
docker run -d -p 6379:6379 redis
```

### 2. Celery Worker μ‹¤ν–‰ (ν•„μ!)
```bash
# Windows
celery -A myproject worker --loglevel=info --pool=solo

# Linux/Mac
celery -A myproject worker --loglevel=info
```

**β οΈ Workerκ°€ μ‹¤ν–‰λμ§€ μ•μΌλ©΄:**
- μ£Όλ¬Έμ€ μƒμ„±λμ§€λ§ (HTTP 202 Accepted)
- μ‹¤μ  μ²λ¦¬(μ¬κ³  μ°¨κ°, ν¬μΈνΈ μ°¨κ°)κ°€ μ• λ©λ‹λ‹¤!

### 3. Django κ°λ° μ„λ²„ μ‹¤ν–‰
```bash
python manage.py runserver
```

### 4. ν…μ¤νΈ λ°μ΄ν„° μƒμ„±
```bash
# μλ™ μƒμ„± μ¤ν¬λ¦½νΈ (κ¶μ¥)
scripts/prepare_load_test.bat  # Windows
scripts/prepare_load_test.sh   # Linux/Mac

# λλ” μλ™ μƒμ„±
python manage.py create_test_data --preset full
python manage.py create_load_test_users --count 1000 --points 50000
```

## λ¶€ν• ν…μ¤νΈ μ‹¤ν–‰

### κΈ°λ³Έ μ‹¤ν–‰
```bash
locust -f shopping/tests/performance/point_concurrent_load_test.py --host=http://localhost:8000
```

μ›Ή λΈλΌμ°μ €μ—μ„ http://localhost:8089 μ ‘μ†

### CLI λ¨λ“ (Headless)
```bash
# 100λ… λ™μ‹ μ‚¬μ©μ, 10λ…/μ΄ μ¦κ°€, 60μ΄ μ‹¤ν–‰
locust -f shopping/tests/performance/point_concurrent_load_test.py \
  --host=http://localhost:8000 \
  --users 100 \
  --spawn-rate 10 \
  --run-time 60s \
  --headless
```

### κ³ λ¶€ν• ν…μ¤νΈ
```bash
# 1000λ… λ™μ‹ μ‚¬μ©μ
locust -f shopping/tests/performance/point_concurrent_load_test.py \
  --host=http://localhost:8000 \
  --users 1000 \
  --spawn-rate 50 \
  --run-time 120s \
  --headless
```

## ν…μ¤νΈ μ‹λ‚λ¦¬μ¤

### PointConcurrentUser (μΌλ° μ‹λ‚λ¦¬μ¤)
- ν¬μΈνΈ μ΅°ν (50%)
- ν¬μΈνΈ μ΄λ ¥ μ΅°ν (30%)
- λ§λ£ μμ • ν¬μΈνΈ μ΅°ν (20%)
- ν¬μΈνΈ μ‚¬μ© μ£Όλ¬Έ (10%)

### PointHighLoadUser (κ³ λ¶€ν• μ‹λ‚λ¦¬μ¤)
- ν¬μΈνΈ μ‚¬μ© μ£Όλ¬Έλ§ μ§‘μ¤‘ ν…μ¤νΈ

## λ¨λ‹ν„°λ§

### Celery Worker λ΅κ·Έ ν™•μΈ
```bash
# Worker μ½μ†”μ—μ„ μ‹¤μ‹κ°„ ν™•μΈ
[2025-11-27 18:00:00,123: INFO/MainProcess] Task order_processing.process_order[...] received
[2025-11-27 18:00:00,456: INFO/ForkPoolWorker] Task succeeded: order_id=123
```

### μ¬κ³  ν™•μΈ
```bash
# Django shellμ—μ„
python manage.py shell

>>> from shopping.models import Product
>>> Product.objects.filter(stock_quantity__gt=0).count()
```

### μ£Όλ¬Έ μ²λ¦¬ μƒνƒ ν™•μΈ
```bash
>>> from shopping.models import Order
>>> Order.objects.filter(status='pending').count()  # μ²λ¦¬ λ€κΈ° μ¤‘
>>> Order.objects.filter(status='paid').count()     # μ²λ¦¬ μ™„λ£
```

## λ¬Έμ  ν•΄κ²°

### "μ¥λ°”κµ¬λ‹κ°€ λΉ„μ–΄μμµλ‹λ‹¤" μ—λ¬
**μ›μΈ**: λ™μ‹μ„± ν™κ²½μ—μ„ μ •μƒμ μΈ μ‹¤ν¨
**ν•΄κ²°**: λ¬΄μ‹ (Locust ν†µκ³„μ— λ°μλ¨)

### μ¬κ³ κ°€ μ°¨κ°λμ§€ μ•μ
**μ›μΈ**: Celery worker λ―Έμ‹¤ν–‰
**ν•΄κ²°**: `celery -A myproject worker --loglevel=info --pool=solo` μ‹¤ν–‰

### Redis μ—°κ²° μ¤λ¥
```
ConnectionError: Error connecting to Redis
```
**ν•΄κ²°**: Redis μ„λ²„ μ‹¤ν–‰ ν™•μΈ (`redis-cli ping` β†’ PONG)

### ν¬μΈνΈκ°€ μ°¨κ°λμ§€ μ•μ
**μ›μΈ**: μ£Όλ¬Έμ΄ λΉ„λ™κΈ° μ²λ¦¬ μ¤‘
**ν™•μΈ**: Celery worker λ΅κ·Έμ—μ„ `Task succeeded` ν™•μΈ

## μ„±λ¥ μ§€ν‘

### μ •μƒ λ²”μ„ (μ°Έκ³ )
- **μ‘λ‹µ μ‹κ°„**:
  - μ΅°ν: < 100ms
  - μ£Όλ¬Έ μƒμ„±: < 500ms (λΉ„λ™κΈ°μ΄λ―€λ΅ λΉ λ¦„)
- **μ„±κ³µλ¥ **: > 95%
- **μ²λ¦¬λ‰**: > 100 RPS (μ„λ²„ μ‚¬μ–‘μ— λ”°λΌ λ‹¤λ¦„)

### μ‹¤ν¨ μ›μΈλ³„ λ¶„ν¬
- μ¥λ°”κµ¬λ‹ λΉ„μ–΄μμ: μ •μƒ (λ™μ‹μ„±)
- μ¬κ³  λ¶€μ΅±: μ •μƒ (ν…μ¤νΈ μ§„ν–‰ μ¤‘)
- ν¬μΈνΈ λ¶€μ΅±: μ •μƒ (ν…μ¤νΈ μ„¤μ •)
- 500 μ—λ¬: λΉ„μ •μƒ β†’ μ„λ²„ λ΅κ·Έ ν™•μΈ ν•„μ”

## μ°Έκ³  μ‚¬ν•­

1. **λΉ„λ™κΈ° μ²λ¦¬**: μ£Όλ¬Έμ€ HTTP 202λ΅ μ¦‰μ‹ μ‘λ‹µν•κ³ , λ°±κ·ΈλΌμ΄λ“μ—μ„ Celeryκ°€ μ²λ¦¬
2. **μ¬κ³  ν™•μΈ μ‹μ **: Celery task μ‹¤ν–‰ μ‹μ μ— μ¬κ³  μ°¨κ°
3. **λ™μ‹μ„± μ μ–΄**: DB λ λ²¨ `select_for_update()`λ΅ μ²λ¦¬
4. **ν…μ¤νΈ κ²©λ¦¬**: κ° μ‚¬μ©μλ” λ…λ¦½μ μΈ μ¥λ°”κµ¬λ‹μ™€ ν¬μΈνΈ λ³΄μ 
